{% extends "layout.html" %}

{% block title %}Abstract Reviewer{% endblock %}

{% block head %}
{{ super() }}
{% endblock %}

{% block content %}
<div class="container">
  <div class="row">
    <div class="col-lg-12 text-left" id="LDA">
        <h1>Finding similar documents - Latent Dirichlet Allocation (LDA)</h1>
        <p>
            <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">LDA</a> is a statistical model used in natural language processing (NLP). 
            It maps a document into a distribution (Dirichlet) of hidden (latent) "topics", which itself is a distribution of words. 
            So you can think of these topics as groupings of associated words. 
            These topics are generated by statistical distribution of words within each document, inside of a corpus of documents.
        </p>
        <p>
            The biggest advantage of LDA is that it makes the data very <strong>explanable</strong>. 
            Topics are simply distribution of words. 
            Therefore, you can get an idea of what each topic by looking at the words with highest weights! 
            This is crucial in many fields, where a black box model cannot be used.
        </p>
        <p>
            On my server, there is a large M x N matrix representing the topic distribution for 260,000 NIH abstracts, 
            where M represents number of abstracts (260K) and N represents number of topics (500).
            <br>
            When an abstract is submitted, this is turned into a 1 x N vector, corresponding to the N topics. 
            This is used to compare which rows of the large matrix above are most similar, using a metric called <a href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen-Shannon divergence</a>. 
            Top 10 are displayed on the page, but 500 are used for word recommendations (<a href="#LinearRegression">below</a>).
        </p>
        <img class="img-responsive" src={{url_for('static', filename='images/LDA.png')}} style="margin: auto; max-width: 700px;" />
    </div>
    <div class="col-lg-12 text-left" id="LinearRegression" style="margin-top:30px;">
        <h1>Ranking words - Logistic & Linear Regression</h1>
        <p>
            A performance/productivity metric is assigned to each NIH grant
            (see details <a href="https://nexus.od.nih.gov/all/2016/10/21/applying-the-relative-citation-ratio-as-a-measure-of-grant-productivity/">here</a>). 
            Logistic & linear regression is performed that predicts this productivity metric, 
            given the word distributions of documents produced by the above algorithm. 
            The resulting coefficient vector from this regression represents effect of each word on the grant performance!
        </p>
        <img class="img-responsive" src={{url_for('static', filename='images/LinearRegression.png')}} style="margin: auto; max-width: 500px;" />
    </div>
    <div class="col-lg-12 text-left" id="ModelPerformance" style="margin-top:30px;">
        <h1>Latest performance levels</h1>
        <p>
            Logistic regression: <strong>10%</strong> increase in accuracy<br>
            Linear regression: <strong>9%</strong> reduction in standard deviation of prediction / actual productivity score
        </p>
    </div>
    <div class="col-lg-12 text-left" id="UseCases" style="margin-top:30px;">
        <h1>Other use cases</h1>
        <p>
            <strong>Recruiting</strong><br>
            Submitted application &harr; Performance review
        </p>
        <p>
            <strong>Customer segmentation</strong><br>
            Demographic information &harr; Customer lifetime value
        </p>
        <p>
            <strong>News / Social media</strong><br>
            Article &harr; Views/Likes/Shares
        </p>
        <p>
            <strong>Images</strong><br>
            Product images (features) &harr; Purchases<br>
            Image segmentation
        </p>
    </div>
  </div>
</div>
{% endblock %}

{% block footer %}
{{ super() }}
{% endblock %}